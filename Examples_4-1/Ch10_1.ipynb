{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "z1EmSFZnIBgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定樣本資料（多個句子）\n",
        "samples = [\"I hated this movie\",\n",
        "       \"This movie is not good\"]"
      ],
      "metadata": {
        "id": "qh_2dJpNIEPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 宣告一個字典變數用於分詞後的結果\n",
        "token_index = {}\n",
        "\n",
        "# 定義分詞用的函式\n",
        "def word_tokenize(text):\n",
        "  text = text.lower()\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "ZvuZbBNGIHp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 每一個句子分別進行分詞\n",
        "# 分詞後取得的各個word分別儲存進token_index，但不會重複儲存\n",
        "for text in samples:\n",
        "  for word in word_tokenize(text):\n",
        "    if word not in token_index:\n",
        "      token_index[word] = len(token_index) + 1\n",
        "            \n",
        "print(token_index) "
      ],
      "metadata": {
        "id": "3uDoi5buIHev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_index.get(\"love\")"
      ],
      "metadata": {
        "id": "ZDe7-kjWLLyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 6 #定義每一個句子最大的單字數\n",
        "results = np.zeros((len(samples), max_length, max(token_index.values())+1 ))  #將結果變數初始化成0\n",
        "\n",
        "# 用雙層迴圈處理並顯示編碼後結果\n",
        "for i, text in enumerate(samples):\n",
        "  words = list(enumerate(word_tokenize(text)))[:max_length]\n",
        "  for j, word in words:\n",
        "    index = token_index.get(word) # 將句子分詞出單字後，取得該單字在token_index裡的index是多少\n",
        "    results[i, j, index] = 1.0  # 將對應index的結果變數設定成1"
      ],
      "metadata": {
        "id": "0BYRhIjgoKoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(samples[0], \"\\n\", results[0])"
      ],
      "metadata": {
        "id": "EW3_lyLcJ7fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(samples[1], \"\\n\", results[1])"
      ],
      "metadata": {
        "id": "DziFvR-0KDBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eDR5VlmNLBi0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ch10_1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}